{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dependencies"
      ],
      "metadata": {
        "id": "s_P2wl3zbsfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdLZ5Te6v_Rw",
        "outputId": "98df8f47-dba2-4a25-e6db-0a0e854e2335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py\n",
        "!wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py\n",
        "!wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py\n",
        "!wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py\n",
        "!wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py\n",
        "!pip install fiftyone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWR-3UvLvyNq",
        "outputId": "f83d12e5-326e-46a4-bcc6-09a878941ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-10 14:40:50--  https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23337 (23K) [text/plain]\n",
            "Saving to: ‘transforms.py’\n",
            "\n",
            "transforms.py       100%[===================>]  22.79K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-06-10 14:40:50 (10.1 MB/s) - ‘transforms.py’ saved [23337/23337]\n",
            "\n",
            "--2023-06-10 14:40:50--  https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4032 (3.9K) [text/plain]\n",
            "Saving to: ‘engine.py’\n",
            "\n",
            "engine.py           100%[===================>]   3.94K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-10 14:40:51 (68.2 MB/s) - ‘engine.py’ saved [4032/4032]\n",
            "\n",
            "--2023-06-10 14:40:51--  https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8388 (8.2K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]   8.19K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-10 14:40:51 (50.9 MB/s) - ‘utils.py’ saved [8388/8388]\n",
            "\n",
            "--2023-06-10 14:40:51--  https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6447 (6.3K) [text/plain]\n",
            "Saving to: ‘coco_eval.py’\n",
            "\n",
            "coco_eval.py        100%[===================>]   6.30K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-10 14:40:52 (75.3 MB/s) - ‘coco_eval.py’ saved [6447/6447]\n",
            "\n",
            "--2023-06-10 14:40:52--  https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8893 (8.7K) [text/plain]\n",
            "Saving to: ‘coco_utils.py’\n",
            "\n",
            "coco_utils.py       100%[===================>]   8.68K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-10 14:40:53 (82.2 MB/s) - ‘coco_utils.py’ saved [8893/8893]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fiftyone\n",
            "  Downloading fiftyone-0.21.0-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from fiftyone)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting argcomplete (from fiftyone)\n",
            "  Downloading argcomplete-3.0.8-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3 (from fiftyone)\n",
            "  Downloading boto3-1.26.151-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.3.0)\n",
            "Collecting dacite<1.8.0,>=1.6.0 (from fiftyone)\n",
            "  Downloading dacite-1.7.0-py3-none-any.whl (12 kB)\n",
            "Collecting Deprecated (from fiftyone)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting eventlet (from fiftyone)\n",
            "  Downloading eventlet-0.33.3-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy (from fiftyone)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.18.3)\n",
            "Collecting hypercorn>=0.13.2 (from fiftyone)\n",
            "  Downloading Hypercorn-0.14.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.1.2)\n",
            "Collecting kaleido (from fiftyone)\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.7.1)\n",
            "Collecting mongoengine==0.24.2 (from fiftyone)\n",
            "  Downloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting motor>=2.5 (from fiftyone)\n",
            "  Downloading motor-3.1.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fiftyone) (23.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.5.3)\n",
            "Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (8.4.0)\n",
            "Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.13.1)\n",
            "Collecting pprintpp (from fiftyone)\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.9.5)\n",
            "Collecting pymongo>=3.12 (from fiftyone)\n",
            "  Downloading pymongo-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2022.7.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from fiftyone) (6.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2022.10.31)\n",
            "Collecting retrying (from fiftyone)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.19.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (67.7.2)\n",
            "Collecting sseclient-py<2,>=1.7.2 (from fiftyone)\n",
            "  Downloading sseclient_py-1.7.2-py2.py3-none-any.whl (8.4 kB)\n",
            "Collecting sse-starlette<1,>=0.10.3 (from fiftyone)\n",
            "  Downloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n",
            "Collecting starlette<0.27,>=0.24.0 (from fiftyone)\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting strawberry-graphql==0.138.1 (from fiftyone)\n",
            "  Downloading strawberry_graphql-0.138.1-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.8.10)\n",
            "Collecting xmltodict (from fiftyone)\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting universal-analytics-python3<2,>=1.0.1 (from fiftyone)\n",
            "  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n",
            "Collecting fiftyone-brain<0.13,>=0.12 (from fiftyone)\n",
            "  Downloading fiftyone_brain-0.12.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fiftyone-db<0.5,>=0.4 (from fiftyone)\n",
            "  Downloading fiftyone_db-0.4.0-py3-none-manylinux1_x86_64.whl (37.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.8/37.8 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting voxel51-eta<0.11,>=0.10 (from fiftyone)\n",
            "  Downloading voxel51_eta-0.10.0-py2.py3-none-any.whl (568 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.9/568.9 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.7.0.72)\n",
            "Collecting graphql-core<3.3.0,>=3.2.0 (from strawberry-graphql==0.138.1->fiftyone)\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (2.8.2)\n",
            "Requirement already satisfied: typing_extensions<5.0.0,>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (4.5.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from fiftyone-brain<0.13,>=0.12->fiftyone) (1.10.1)\n",
            "Collecting h11 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2>=3.1.0 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting priority (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.10.2)\n",
            "Collecting wsproto>=0.14.0 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3->fiftyone) (2.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.14->fiftyone) (8.2.2)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo>=3.12->fiftyone)\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.27,>=0.24.0->fiftyone) (3.6.2)\n",
            "Collecting httpx>=0.10.0 (from universal-analytics-python3<2,>=1.0.1->fiftyone)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.11,>=0.10->fiftyone) (0.7)\n",
            "Collecting jsonlines (from voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Collecting py7zr (from voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading py7zr-0.20.5-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rarfile (from voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.11,>=0.10->fiftyone) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.11,>=0.10->fiftyone) (1.16.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.11,>=0.10->fiftyone) (2.4.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.11,>=0.10->fiftyone) (4.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.11,>=0.10->fiftyone) (1.26.15)\n",
            "Collecting botocore<1.30.0,>=1.29.151 (from boto3->fiftyone)\n",
            "  Downloading botocore-1.29.151-py3-none-any.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->fiftyone)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->fiftyone)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->fiftyone) (1.14.1)\n",
            "Requirement already satisfied: greenlet>=0.3 in /usr/local/lib/python3.10/dist-packages (from eventlet->fiftyone) (2.0.2)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->fiftyone) (0.2.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (3.0.9)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (1.4.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (3.1.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.27,>=0.24.0->fiftyone) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.27,>=0.24.0->fiftyone) (1.3.0)\n",
            "Collecting hyperframe<7,>=6.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2022.12.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone)\n",
            "  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->voxel51-eta<0.11,>=0.10->fiftyone) (23.1.0)\n",
            "Collecting texttable (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.6.6 (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.14.4 (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading pyzstd-0.15.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (399 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.3/399.3 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1 (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading pyppmd-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj>=0.6.0 (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading pybcj-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting brotli>=1.0.9 (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflate64>=0.3.1 (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading inflate64-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->voxel51-eta<0.11,>=0.10->fiftyone) (2.0.12)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal->voxel51-eta<0.11,>=0.10->fiftyone) (0.1.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal->voxel51-eta<0.11,>=0.10->fiftyone) (2023.3)\n",
            "Installing collected packages: texttable, sseclient-py, rarfile, pprintpp, kaleido, brotli, xmltodict, retrying, pyzstd, pyppmd, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, jmespath, inflate64, hyperframe, hpack, h11, graphql-core, ftfy, fiftyone-db, dnspython, dill, Deprecated, dacite, argcomplete, aiofiles, wsproto, strawberry-graphql, starlette, pymongo, py7zr, httpcore, h2, eventlet, botocore, voxel51-eta, sse-starlette, s3transfer, motor, mongoengine, hypercorn, httpx, fiftyone-brain, universal-analytics-python3, boto3, fiftyone\n",
            "Successfully installed Deprecated-1.2.14 aiofiles-23.1.0 argcomplete-3.0.8 boto3-1.26.151 botocore-1.29.151 brotli-1.0.9 dacite-1.7.0 dill-0.3.6 dnspython-2.3.0 eventlet-0.33.3 fiftyone-0.21.0 fiftyone-brain-0.12.0 fiftyone-db-0.4.0 ftfy-6.1.1 graphql-core-3.2.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-0.17.2 httpx-0.24.1 hypercorn-0.14.3 hyperframe-6.0.1 inflate64-0.3.1 jmespath-1.0.1 jsonlines-3.1.0 kaleido-0.2.1 mongoengine-0.24.2 motor-3.1.2 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.20.5 pybcj-1.0.1 pycryptodomex-3.18.0 pymongo-4.3.3 pyppmd-1.0.0 pyzstd-0.15.7 rarfile-4.0 retrying-1.3.4 s3transfer-0.6.1 sse-starlette-0.10.3 sseclient-py-1.7.2 starlette-0.26.1 strawberry-graphql-0.138.1 texttable-1.6.7 universal-analytics-python3-1.1.1 voxel51-eta-0.10.0 wsproto-1.2.0 xmltodict-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dependencies"
      ],
      "metadata": {
        "id": "tHSh3c1ycA2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "import fiftyone.utils.coco as fouc\n",
        "\n",
        "import utils\n",
        "import transforms as T\n",
        "from engine import train_one_epoch, evaluate\n",
        "\n",
        "from PIL import Image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T08:24:38.615373Z",
          "iopub.execute_input": "2023-06-09T08:24:38.616378Z",
          "iopub.status.idle": "2023-06-09T08:24:41.950621Z",
          "shell.execute_reply.started": "2023-06-09T08:24:38.616339Z",
          "shell.execute_reply": "2023-06-09T08:24:41.949666Z"
        },
        "trusted": true,
        "id": "1uAVkyBsYuH2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3520e37-2fe3-4918-f8df-1b35b067a393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Migrating database to v0.21.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.migrations.runner:Migrating database to v0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset"
      ],
      "metadata": {
        "id": "-QJEpLdncII_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the COCO-2017 dataset\n",
        "# This will download it from the FiftyOne Dataset Zoo if necessary\n",
        "train_dataset = foz.load_zoo_dataset(\"coco-2017\", split=\"train\", label_types=[\"detections\"], classes=[\"person\"], max_samples=3000)\n",
        "test_dataset = foz.load_zoo_dataset(\"coco-2017\", split=\"validation\", label_types=[\"detections\"], classes=[\"person\"], max_samples=500)\n",
        "\n",
        "# Print summary information about the view\n",
        "print(train_dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T08:24:51.804187Z",
          "iopub.execute_input": "2023-06-09T08:24:51.804611Z",
          "iopub.status.idle": "2023-06-09T08:24:51.810305Z",
          "shell.execute_reply.started": "2023-06-09T08:24:51.804569Z",
          "shell.execute_reply": "2023-06-09T08:24:51.809169Z"
        },
        "trusted": true,
        "id": "svZ8O3LIYuH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c343398e-bbde-440f-e1c8-a23533a329cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |██████|    1.9Gb/1.9Gb [16.6s elapsed, 0s remaining, 131.0Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |██████|    1.9Gb/1.9Gb [16.6s elapsed, 0s remaining, 131.0Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 3000 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading 3000 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |████████████████| 3000/3000 [25.5m elapsed, 0s remaining, 2.0 images/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |████████████████| 3000/3000 [25.5m elapsed, 0s remaining, 2.0 images/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing annotations for 3000 downloaded samples to '/root/fiftyone/coco-2017/train/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Writing annotations for 3000 downloaded samples to '/root/fiftyone/coco-2017/train/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'coco-2017' split 'train'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'train'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 3000/3000 [31.8s elapsed, 0s remaining, 78.9 samples/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 3000/3000 [31.8s elapsed, 0s remaining, 78.9 samples/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'coco-2017-train-3000' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-train-3000' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 500 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading 500 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |██████████████████| 500/500 [4.2m elapsed, 0s remaining, 1.9 images/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |██████████████████| 500/500 [4.2m elapsed, 0s remaining, 1.9 images/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing annotations for 500 downloaded samples to '/root/fiftyone/coco-2017/validation/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Writing annotations for 500 downloaded samples to '/root/fiftyone/coco-2017/validation/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 500/500 [7.2s elapsed, 0s remaining, 113.8 samples/s]     \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 500/500 [7.2s elapsed, 0s remaining, 113.8 samples/s]     \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'coco-2017-validation-500' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-validation-500' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name:        coco-2017-train-3000\n",
            "Media type:  image\n",
            "Num samples: 3000\n",
            "Persistent:  False\n",
            "Tags:        []\n",
            "Sample fields:\n",
            "    id:           fiftyone.core.fields.ObjectIdField\n",
            "    filepath:     fiftyone.core.fields.StringField\n",
            "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the dataset\n",
        "for sample in train_dataset:\n",
        "    # Get the detections\n",
        "    detections = sample.ground_truth.detections\n",
        "    # Filter out non-person detections\n",
        "    detections = [d for d in detections if d.label == \"person\"]\n",
        "    # Update the detections\n",
        "    sample.ground_truth.detections = detections\n",
        "    # Save the sample\n",
        "    sample.save()"
      ],
      "metadata": {
        "id": "Q2QPpxsPxD3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the dataset\n",
        "for sample in test_dataset:\n",
        "    # Get the detections\n",
        "    detections = sample.ground_truth.detections\n",
        "    # Filter out non-person detections\n",
        "    detections = [d for d in detections if d.label == \"person\"]\n",
        "    # Update the detections\n",
        "    sample.ground_truth.detections = detections\n",
        "    # Save the sample\n",
        "    sample.save()"
      ],
      "metadata": {
        "id": "Ss-434eIxE_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Object Dataset"
      ],
      "metadata": {
        "id": "kdNwbE2JcYhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ObjectDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, root, transforms=None):\n",
        "    #please define the data proses init\n",
        "    self.root = root\n",
        "    self.transforms = transforms\n",
        "\n",
        "    self.img_paths = self.root.values(\"filepath\")\n",
        "\n",
        "    self.classes = self.root.distinct(\"%s.detections.label\" % \"ground_truth\")\n",
        "    if self.classes[0] != \"background\":\n",
        "        self.classes = [\"background\"] + self.classes\n",
        "\n",
        "    self.labels_map_rev = {c: i for i, c in enumerate(self.classes)}\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # please define the dataloader\n",
        "    img_path = self.img_paths[idx]\n",
        "    sample_img = self.root[img_path]\n",
        "    metadata = sample_img.metadata\n",
        "\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "    boxes = []\n",
        "    labels = []\n",
        "    image_id = []\n",
        "    area = []\n",
        "    iscrowd = []\n",
        "\n",
        "    for det in sample_img[\"ground_truth\"].detections:\n",
        "      category_id = self.labels_map_rev[det.label]\n",
        "      coco_obj = fouc.COCOObject.from_label(\n",
        "          det, metadata, category_id=category_id,\n",
        "      )\n",
        "      x, y, w, h = coco_obj.bbox\n",
        "      boxes.append([x, y, x + w, y + h])\n",
        "      labels.append(coco_obj.category_id)\n",
        "      area.append(coco_obj.area)\n",
        "      iscrowd.append(coco_obj.iscrowd)\n",
        "\n",
        "    target = {}\n",
        "    target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "    target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
        "    target[\"image_id\"] = torch.as_tensor([idx])\n",
        "    target[\"area\"] = torch.as_tensor(area, dtype=torch.float32)\n",
        "    target[\"iscrowd\"] = torch.as_tensor(iscrowd, dtype=torch.int64)\n",
        "\n",
        "    if self.transforms is not None: #preprocessing dan augmentasi\n",
        "      img, target = self.transforms(img, target)\n",
        "\n",
        "    return img, target\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_paths)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T08:24:59.843106Z",
          "iopub.execute_input": "2023-06-09T08:24:59.843469Z",
          "iopub.status.idle": "2023-06-09T08:24:59.855369Z",
          "shell.execute_reply.started": "2023-06-09T08:24:59.843438Z",
          "shell.execute_reply": "2023-06-09T08:24:59.854421Z"
        },
        "trusted": true,
        "id": "tN3ZqcXoYuIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Transforms"
      ],
      "metadata": {
        "id": "Z1ax_Z9hcdMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    transforms.append(T.PILToTensor())\n",
        "    transforms.append(T.ConvertImageDtype(torch.float))\n",
        "    if train:\n",
        "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "\n",
        "    return T.Compose(transforms)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T08:25:01.354249Z",
          "iopub.execute_input": "2023-06-09T08:25:01.354636Z",
          "iopub.status.idle": "2023-06-09T08:25:01.360218Z",
          "shell.execute_reply.started": "2023-06-09T08:25:01.354604Z",
          "shell.execute_reply": "2023-06-09T08:25:01.359077Z"
        },
        "trusted": true,
        "id": "s0HgAAIrYuID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply Transformations and Dataloader"
      ],
      "metadata": {
        "id": "UpNkowq6cmCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "\n",
        "# Use our dataset and defined transformations\n",
        "train_data = ObjectDataset(train_dataset, get_transform(train=True))\n",
        "test_data = ObjectDataset(test_dataset, get_transform(train=False))\n",
        "\n",
        "# Define training and validation data loaders\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "  train_data, batch_size=batch_size, shuffle=True, num_workers=2,\n",
        "  collate_fn=utils.collate_fn)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "  test_data, batch_size=batch_size, shuffle=False, num_workers=2,\n",
        "  collate_fn=utils.collate_fn)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T08:25:04.684509Z",
          "iopub.execute_input": "2023-06-09T08:25:04.685269Z",
          "iopub.status.idle": "2023-06-09T08:25:05.903466Z",
          "shell.execute_reply.started": "2023-06-09T08:25:04.685232Z",
          "shell.execute_reply": "2023-06-09T08:25:05.902422Z"
        },
        "trusted": true,
        "id": "2h5jghJXYuIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model"
      ],
      "metadata": {
        "id": "CU-3jbW5YuII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resnet50_FPN"
      ],
      "metadata": {
        "id": "P9sByUqPYuIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "# load a model pre-trained pre-trained on COCO\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "# get number of input features for the classifier\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "# replace the pre-trained head with a new one\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-07T06:12:04.546328Z",
          "iopub.execute_input": "2023-06-07T06:12:04.546749Z",
          "iopub.status.idle": "2023-06-07T06:12:06.051262Z",
          "shell.execute_reply.started": "2023-06-07T06:12:04.546717Z",
          "shell.execute_reply": "2023-06-07T06:12:06.050246Z"
        },
        "trusted": true,
        "id": "8mG8TLf9YuIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet18"
      ],
      "metadata": {
        "id": "w1VbgLA8YuIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = torchvision.models.resnet18(weights=\"DEFAULT\")\n",
        "backbone = torch.nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "backbone.out_channels = 512\n",
        "\n",
        "anchor_generator = AnchorGenerator()\n",
        "\n",
        "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names= ['0'], output_size=7, sampling_ratio=2)\n",
        "\n",
        "resnet_model = FasterRCNN(backbone, num_classes=2, rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T06:36:38.331824Z",
          "iopub.execute_input": "2023-06-09T06:36:38.332201Z",
          "iopub.status.idle": "2023-06-09T06:36:39.355714Z",
          "shell.execute_reply.started": "2023-06-09T06:36:38.332168Z",
          "shell.execute_reply": "2023-06-09T06:36:39.354755Z"
        },
        "trusted": true,
        "id": "UaiLLsMOYuIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72de3484-c63b-4adc-8493-b66bd2888a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 86.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GoogleNet"
      ],
      "metadata": {
        "id": "5D9e4erMcrfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# backbone googlenet\n",
        "googlenet = torchvision.models.googlenet(weights=\"DEFAULT\")\n",
        "\n",
        "backbone = torch.nn.Sequential(*list(googlenet.children())[:-3]) # menghilangkan fully connected layer dan global avg pool\n",
        "\n",
        "backbone.out_channels = 1024\n",
        "\n",
        "anchor_generator = AnchorGenerator()\n",
        "\n",
        "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names= ['0'], output_size=7, sampling_ratio=2)\n",
        "\n",
        "googlenet = FasterRCNN(backbone, num_classes=2, rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler)"
      ],
      "metadata": {
        "id": "pkzMKTFPctqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "613cd873-0895-48ed-f224-3031e38577c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n",
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 133MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG16"
      ],
      "metadata": {
        "id": "AsqNVMSsYuIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = torchvision.models.vgg16(weights=\"DEFAULT\")\n",
        "backbone = vgg16.features\n",
        "\n",
        "backbone.out_channels = 512\n",
        "\n",
        "anchor_generator = AnchorGenerator()\n",
        "\n",
        "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names= ['0'], output_size=7, sampling_ratio=2)\n",
        "\n",
        "vgg16_model = FasterRCNN(backbone, num_classes=2, rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T08:25:09.563250Z",
          "iopub.execute_input": "2023-06-09T08:25:09.564504Z",
          "iopub.status.idle": "2023-06-09T08:25:14.698423Z",
          "shell.execute_reply.started": "2023-06-09T08:25:09.564460Z",
          "shell.execute_reply": "2023-06-09T08:25:14.697449Z"
        },
        "trusted": true,
        "id": "dc0pVaQEYuIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5a4163-472f-4b5c-81a1-d41dfe2ea881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 86.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluate Model"
      ],
      "metadata": {
        "id": "LqMwAa_AePjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_dataloader, test_dataloader, num_epochs=5):\n",
        "\n",
        "    # train on the GPU or on the CPU, if a GPU is not available\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    # construct an optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "    # and a learning rate scheduler\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "    # move model to the right device\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # train for one epoch, printing every 10 iterations\n",
        "        train_one_epoch(model, optimizer, train_dataloader, device, epoch, print_freq=150)\n",
        "\n",
        "        # update the learning rate\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # save current epoch model\n",
        "        torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "        }, \"/content/drive/MyDrive/last_model.pt\")\n",
        "\n",
        "        # evaluate on the test dataset\n",
        "        evaluate(model, test_dataloader, device=device)\n",
        "\n",
        "    print(\"That's it!\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T08:25:23.064317Z",
          "iopub.execute_input": "2023-06-09T08:25:23.064762Z",
          "iopub.status.idle": "2023-06-09T08:25:23.076860Z",
          "shell.execute_reply.started": "2023-06-09T08:25:23.064711Z",
          "shell.execute_reply": "2023-06-09T08:25:23.075923Z"
        },
        "trusted": true,
        "id": "jNj9S-5sYuIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(vgg16_model, train_dataloader, test_dataloader, 20)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T08:25:27.783179Z",
          "iopub.execute_input": "2023-06-09T08:25:27.783547Z",
          "iopub.status.idle": "2023-06-09T12:34:37.205717Z",
          "shell.execute_reply.started": "2023-06-09T08:25:27.783499Z",
          "shell.execute_reply": "2023-06-09T12:34:37.204029Z"
        },
        "trusted": true,
        "id": "dPjSBjnzYuIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model"
      ],
      "metadata": {
        "id": "1Cd0ulWkeXx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "root_dir = \"/content/drive/MyDrive/Person_Tracking\"\n",
        "googlenet_dir = os.path.join(root_dir, \"googlenet/last_model.pt\")\n",
        "vgg16_dir = os.path.join(root_dir, \"vgg16/last_model.pt\")\n",
        "resnet18_dir = os.path.join(root_dir, \"resnet18/last_model.pt\")"
      ],
      "metadata": {
        "id": "-Mu-R0Oz8hdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(googlenet_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49zoGX_L_umT",
        "outputId": "8b20772b-8dec-4838-a9b6-93d7504e8d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Person_Tracking/googlenet/last_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "pWiAZzDT-0az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqIn8QUJ_aSA",
        "outputId": "4ec9c615-eff9-469c-89d3-1c86bde8026a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load ResNet18 Model"
      ],
      "metadata": {
        "id": "r10RLG1J8vr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.to(device)\n",
        "checkpoint_resnet18 = torch.load(resnet18_dir)\n",
        "resnet_model.load_state_dict(checkpoint_resnet18['model_state_dict'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-09T04:00:12.490047Z",
          "iopub.execute_input": "2023-06-09T04:00:12.490437Z",
          "iopub.status.idle": "2023-06-09T04:00:12.776568Z",
          "shell.execute_reply.started": "2023-06-09T04:00:12.490398Z",
          "shell.execute_reply": "2023-06-09T04:00:12.775602Z"
        },
        "trusted": true,
        "id": "4EI-9pNJYuIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load VGG16 Model"
      ],
      "metadata": {
        "id": "Uzv8N8Q5ADtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model.to(device)\n",
        "checkpoint_vgg16 = torch.load(vgg16_dir)\n",
        "vgg16_model.load_state_dict(checkpoint_vgg16['model_state_dict'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-07T15:01:16.712098Z",
          "iopub.execute_input": "2023-06-07T15:01:16.712463Z",
          "iopub.status.idle": "2023-06-07T15:01:17.682276Z",
          "shell.execute_reply.started": "2023-06-07T15:01:16.712432Z",
          "shell.execute_reply": "2023-06-07T15:01:17.681182Z"
        },
        "trusted": true,
        "id": "ERSRiiFGYuIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Googlenet Model"
      ],
      "metadata": {
        "id": "FC5CUA7EAHaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "googlenet.to(device)\n",
        "checkpoint_googlenet = torch.load(googlenet_dir)\n",
        "googlenet.load_state_dict(checkpoint_googlenet['model_state_dict'])"
      ],
      "metadata": {
        "id": "JYgZUxWO-G7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Detection"
      ],
      "metadata": {
        "id": "gI_l0K5t7wkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"background\", \"person\"]"
      ],
      "metadata": {
        "id": "y5Wb_Xx7HwG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import random\n",
        "\n",
        "def plot_one_box(x, img, color=None, label=None, line_thickness=3):\n",
        "    # Plots one bounding box on image img\n",
        "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
        "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
        "    c1, c2 = x[0], x[1]\n",
        "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
        "    if label:\n",
        "        tf = max(tl - 1, 1)  # font thickness\n",
        "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
        "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
        "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
        "\n",
        "def detect(img, model, threshold=0.5):\n",
        "  model.eval()\n",
        "  # Run inference\n",
        "  t0 = time.time()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    img = Image.fromarray(img)\n",
        "    img = T.PILToTensor()(img)\n",
        "    img = T.ConvertImageDtype(torch.float)(img[0])\n",
        "    img = img[0].unsqueeze(0).to(device)\n",
        "    pred = model(img)\n",
        "\n",
        "  print(f'[INFO]: Inference Time ({time.time() - t0:.3f}s)')\n",
        "  pred_class = [class_names[i] for i in list(pred[0]['labels'].cpu().numpy())]\n",
        "  pred_boxes = [[(int(i[0]), int(i[1])), (int(i[2]), int(i[3]))] for i in list(pred[0]['boxes'].cpu().detach().numpy())]\n",
        "  pred_score = list(pred[0]['scores'].cpu().detach().numpy())\n",
        "  pred_t = [pred_score.index(x) for x in pred_score if x>threshold][-1]\n",
        "  pred_boxes = pred_boxes[:pred_t+1]\n",
        "  pred_class = pred_class[:pred_t+1]\n",
        "  pred_score = pred_score[:pred_t+1]\n",
        "  return pred_boxes, pred_class,pred_score\n",
        ""
      ],
      "metadata": {
        "id": "ptNLnbIm7zYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('image2.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "boxes, classes, scores = detect(img, resnet_model, 0.8)\n",
        "print(f'[INFO]: Plotting image...')\n",
        "if boxes:\n",
        "  for i, box in enumerate(boxes):\n",
        "    plot_one_box(box,img, label=\"{} {:.2f}\".format(classes[i], scores[i]))\n",
        "plt.figure(figsize=(5,10))\n",
        "plt.imshow(img)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_KugwxQDopD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(\"tes.mp4\")\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "vid_writer = cv2.VideoWriter(\n",
        "    'output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
        "\n",
        "while True:\n",
        "    _, img = cap.read()\n",
        "    if not _:\n",
        "        break\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    boxes, classes, scores = detect(img, resnet_model, 0.8)\n",
        "    if boxes:\n",
        "      for i, box in enumerate(boxes):\n",
        "        plot_one_box(box,img, label=\"{} {:.2f}\".format(classes[i], scores[i]))\n",
        "    print(img.shape)\n",
        "    # img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    vid_writer.write(img)\n",
        "vid_writer.release()\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "lPdzjfYhos4k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}